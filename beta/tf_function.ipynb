{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISubpr_SSsiM"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jTMb1dySr3V"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6DWfyNThSziV"
   },
   "source": [
    "# tf.function\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/beta/tutorials/eager/tf_function\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />TensorFlow.org에서 보기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/ko/beta/tutorials/eager/tf_function.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/ko/beta/tutorials/eager/tf_function.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />깃허브(GitHub) 소스 보기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J122XQYG7W6w"
   },
   "source": [
    "텐서플로 2.0에서는 즉시 실행(eager execution)이 기본적으로 실행됩니다. 이는 매우 직관적이고 유연한 유저 인터페이스를 제공합니다.(일회성 연산을 실행하는 게 훨씬 쉽고 빠릅니다) 그러나 어느 정도 성능과 전개성(배포 가능성)을 희생시켜야 가능할 수 있습니다.  \n",
    "In TensorFlow 2.0 eager execution is turned on by default. This gets you a very\n",
    "intuitive and flexible user interface (running one-off operations is much easier\n",
    "and faster) but this can come at the expense of performance and deployability.\n",
    "\n",
    "최상의 성능을 얻고 모델을 어디에서나 배포 가능하게 할 수 있도록, 프로그램의 그래프를 만들 수 있는 도구로 `tf.funtion`을 제공합니다.\n",
    "To get peak performance and to make your model deployable anywhere, we provide\n",
    "`tf.function` as the tool you can use to make graphs out of your programs.\n",
    "오토그래프 덕분에, 놀라운 양의 파이썬 코드가 tf.function과 함께 간단히 작동됩니다. 하지만 여전히 몇 가지 주의해야 할 점들이 있습니다.\n",
    "Thanks to AutoGraph, a surprising amount of Python code just works with\n",
    "tf.function, but there are still pitfalls to be wary of.\n",
    "\n",
    "주요 요점 및 권장사항:\n",
    "The main takeaways and recommendations are:\n",
    "\n",
    "- 객체 번형이나 리스트 추가와 같은 파이썬 부수 효과에 의존하지 마세요.\n",
    "- tf.function은 넘파이 연산이나 파이썬 기본 자료형 보다는 텐서플로 연산과 가장 잘 작동합니다.\n",
    "- 의구심이 생길경우, `for x in y` 구문이 작동할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "otIdN1TS8N7S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-nightly-2.0-preview\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Could not find a version that satisfies the requirement tf-nightly-2.0-preview (from versions: none)\n",
      "ERROR: No matching distribution found for tf-nightly-2.0-preview\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "!pip install tf-nightly-2.0-preview\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D25apou9IOXa"
   },
   "outputs": [],
   "source": [
    "import contextlib\n",
    "\n",
    "# 발생할 수 있는 오류를 보여주는 몇가지 헬퍼 코드입니다.\n",
    "@contextlib.contextmanager\n",
    "def assert_raises(error_class):\n",
    "  try:\n",
    "    yield\n",
    "  except error_class as e:\n",
    "    print('예상된 예외 \\n  {}: {}'.format(error_class, e))\n",
    "  except Exception as e:\n",
    "    print('예상되지 않은 예외 \\n  {}: {}'.format(type(e), e))\n",
    "  else:\n",
    "    raise Exception('{}가 발생할 것으로 예상되나, 오류가 발생하지 않았습니다!'.format(\n",
    "        error_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfayNj-ZIkIB"
   },
   "source": [
    "정의한 `tf.function`은 마치 텐서플로 연산과 같습니다. 즉각적으로 실행할 수 있고, 그래프로 사용할 수 있고, 그래디언트 등을 가지고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbtT1-Wm70F2"
   },
   "outputs": [],
   "source": [
    "# 연산 같은 함수\n",
    "\n",
    "@tf.function\n",
    "def add(a, b):\n",
    "  return a + b\n",
    "\n",
    "add(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uP-zUelB8DbX"
   },
   "outputs": [],
   "source": [
    "# 그래디언트를 포함한 함수\n",
    "\n",
    "@tf.function\n",
    "def add(a, b):\n",
    "  return a + b\n",
    "\n",
    "v = tf.Variable(1.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  result = add(v, 1.0)\n",
    "tape.gradient(result, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l5qRjdbBVdU6"
   },
   "outputs": [],
   "source": [
    "# 함수 속에 함수들을 사용할 수 있습니다.\n",
    "\n",
    "@tf.function\n",
    "def dense_layer(x, w, b):\n",
    "  return add(tf.matmul(x, w), b)\n",
    "\n",
    "dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZ4Do2AV80cO"
   },
   "source": [
    "## 추적과 다형성 Tracing and Polymorphism\n",
    "\n",
    "파이썬의 동적 타이핑은 다양한 타입의 매개변수로 함수를 호출할 수 있다는 것을 의미합니다. 파이썬은 각 시나리오마다 다른 것을 수행할 것입니다. 반면에, 텐서플로 그래프는 정적 데이터 타입과 형태의 차원이 필요합니다. `tf.function`은 올바른 그래프를 생성할 필요가 있을 때 함수를 되돌아가 이 둘 사이의 차이를 연결합니다. `tf.function` 사용법의 중요 세부 요소들은 대부분 이렇게 돌아가는 과정에서 생겨납니다. \n",
    "\n",
    "어떠한 상황이 일어났는지 보기 위해 다른 타입의 매개변수를 사용하여 함수를 호출할 수 있습니다.\n",
    "\n",
    "On the other hand, TensorFlow graphs require static dtypes and shape dimensions. `tf.function` bridges this gap by retracing the function when necessary to generate the correct graphs. Most of the subtlety of `tf.function` usage stems from this retracing behavior.\n",
    "\n",
    "You can call a function with arguments of different types to see what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kojmJrgq8U9v"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0606 17:59:10.771329 28908 tf_logging.py:161] Entity <function double at 0x0000021B76048048> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: (unicode error) 'utf-8' codec can't decode byte 0xc3 in position 0: invalid continuation byte (tmpbl86aj26.py, line 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function double at 0x0000021B76048048> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: (unicode error) 'utf-8' codec can't decode byte 0xc3 in position 0: invalid continuation byte (tmpbl86aj26.py, line 5)\n",
      "추적 Tensor(\"a:0\", shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0606 17:59:10.982763 28908 tf_logging.py:161] Entity <function double at 0x0000021B76048048> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: (unicode error) 'utf-8' codec can't decode byte 0xc3 in position 0: invalid continuation byte (tmpmiquo6dv.py, line 5)\n",
      "W0606 17:59:11.052576 28908 tf_logging.py:161] Entity <function double at 0x0000021B76048048> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: (unicode error) 'utf-8' codec can't decode byte 0xc3 in position 0: invalid continuation byte (tmp7g5m2dns.py, line 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function double at 0x0000021B76048048> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: (unicode error) 'utf-8' codec can't decode byte 0xc3 in position 0: invalid continuation byte (tmpmiquo6dv.py, line 5)\n",
      "추적 Tensor(\"a:0\", shape=(), dtype=float32)\n",
      "tf.Tensor(2.2, shape=(), dtype=float32)\n",
      "\n",
      "WARNING: Entity <function double at 0x0000021B76048048> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: (unicode error) 'utf-8' codec can't decode byte 0xc3 in position 0: invalid continuation byte (tmp7g5m2dns.py, line 5)\n",
      "추적 Tensor(\"a:0\", shape=(), dtype=string)\n",
      "tf.Tensor(b'aa', shape=(), dtype=string)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 함수의 다형성\n",
    "\n",
    "@tf.function\n",
    "def double(a):\n",
    "  print(\"추적\", a)\n",
    "  return a + a\n",
    "\n",
    "print(double(tf.constant(1)))\n",
    "print()\n",
    "print(double(tf.constant(1.1)))\n",
    "print()\n",
    "print(double(tf.constant(\"a\")))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4pJqkDR_Q2wz"
   },
   "source": [
    "추적 동향을 제어하기 위해서는 다음 기술들을 참고하세요.\n",
    "To control the tracing behavior, use the following techniques:\n",
    "\n",
    "- 새로운 `tf.function` 생성: 분리된 `tf.function` 객체는 추적이 공유되지 않게 보장됩니다. or 추적을 공유할 수 없게 \n",
    "- `get_concrete_function` 특정한 추적을 얻기 위한 메소드 사용\n",
    "- Specify `input_signature` when calling `tf.function` to ensure only one function graph will be built.\n",
    "- 하나의 function 그래프기 빌드되기위해 `tf.function`을 호출할때 특정한 `input_signatur` 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHg2CGtPQ3Hz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0606 17:59:59.622725 28908 tf_logging.py:161] Entity <function double at 0x0000021B76048048> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: (unicode error) 'utf-8' codec can't decode byte 0xc3 in position 0: invalid continuation byte (tmpg3o8lgq2.py, line 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구체적인 추적 얻기\n",
      "WARNING: Entity <function double at 0x0000021B76048048> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: (unicode error) 'utf-8' codec can't decode byte 0xc3 in position 0: invalid continuation byte (tmpg3o8lgq2.py, line 5)\n",
      "추적 Tensor(\"a:0\", dtype=string)\n",
      "추적된 함수 실행\n",
      "tf.Tensor(b'aa', shape=(), dtype=string)\n",
      "tf.Tensor(b'bb', shape=(), dtype=string)\n",
      "적절하지 않는 종류의 추적을 사용할 경우 오류가 발생할 수 있습니다.\n",
      "예상된 예외 \n",
      "  <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>: cannot compute __inference_double_33 as input #0(zero-based) was expected to be a string tensor but is a int32 tensor [Op:__inference_double_33]\n"
     ]
    }
   ],
   "source": [
    "print(\"구체적인 추적 얻기\")\n",
    "double_strings = double.get_concrete_function(tf.TensorSpec(shape=None, dtype=tf.string))\n",
    "print(\"추적된 함수 실행\")\n",
    "print(double_strings(tf.constant(\"a\")))\n",
    "print(double_strings(a=tf.constant(\"b\")))\n",
    "print(\"적절하지 않는 종류의 추적을 사용할 경우 오류가 발생할 수 있습니다.\")\n",
    "with assert_raises(tf.errors.InvalidArgumentError):\n",
    "  double_strings(tf.constant(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BDMIRmu1RGB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0606 18:00:43.988104 28908 tf_logging.py:161] Entity <function next_collatz at 0x0000021B770936A8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: (unicode error) 'utf-8' codec can't decode byte 0xc3 in position 0: invalid continuation byte (tmpnjw8q_v6.py, line 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function next_collatz at 0x0000021B770936A8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: (unicode error) 'utf-8' codec can't decode byte 0xc3 in position 0: invalid continuation byte (tmpnjw8q_v6.py, line 5)\n",
      "추적 Tensor(\"x:0\", shape=(None,), dtype=int32)\n",
      "tf.Tensor([4 1], shape=(2,), dtype=int32)\n",
      "예상된 예외 \n",
      "  <class 'ValueError'>: Python inputs incompatible with input_signature: inputs ((<tf.Tensor: id=60, shape=(2, 2), dtype=int32, numpy=\n",
      "array([[1, 2],\n",
      "       [3, 4]])>,)), input_signature ((TensorSpec(shape=(None,), dtype=tf.int32, name=None),))\n"
     ]
    }
   ],
   "source": [
    "@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))\n",
    "def next_collatz(x):\n",
    "  print(\"추적\", x)\n",
    "  return tf.where(tf.equal(x % 2, 0), x // 2, 3 * x + 1)\n",
    "\n",
    "print(next_collatz(tf.constant([1, 2])))\n",
    "# 입력 시그니쳐에 1-D 텐서를 주었으므로, 오류가 발생할 것입니다.\n",
    "with assert_raises(ValueError):\n",
    "  next_collatz(tf.constant([[1, 2], [3, 4]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Es0WZkLIUSdu"
   },
   "source": [
    "## When to retrace?\n",
    "다형성을 가지고 있는 `tf.function`은 추적과정에서 생성된 구체적인 함수들의 캐시를 유지합니다. 캐시의 키들은 함수의 매개변수와 주요 매개변수에서 생성된 효과적인 키의 튜플입니다. 키는 \n",
    "A polymorphic `tf.function` keeps a cache of concrete functions generated by tracing. The cache keys are effectively tuples of keys generated from the function args and kwargs. `tf.Tensor`에 대해 생성된 키는 `tf.Tensor`의 형태와 타입입니다. 파이썬에 대해 생성된 키는 파이썬 프리메티브의 값을 나타냅니다. The key generated for a `tf.Tensor` argument is its shape and type. The key generated for a Python primitive is its value. For all other Python types, the keys are based on the object `id()` so that methods are traced independently for each instance of a class. 앞으로, 텐서플로 더욱 정교한 캐쉬를 추가할 것입니다. In the future, TensorFlow may add more sophisticated caching for Python objects that can be safely converted to tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AY5oiQN0XIyA"
   },
   "source": [
    "## 파이썬 또는 텐서 매개변수?\n",
    "\n",
    "그래프의 구조와 하이퍼파라미터(hyperparameter)를 제어하기위해 파이썬 매개변수가 자주 사용됩니다. 예를 들면 `num_layers=10` 또는 `training=True` 또는 `nonlinearity='relu'` 등이 있습니다. 그래서 만약 파이썬 매개변수가 변경된다면 그래프를 다시 추적하는 것이 이치에 맞습니다. \n",
    "\n",
    "그러나, 파이썬 매개변수가 그래프 구조를 제어하는데 사용되지 않을 수도 있습니다. 이럴 경우, 파이썬 값을 변경하는 것은 불필요한 추적을 발생시킬 수 있습니다. 예를 들면, 오토 그래프가 동적으로 전개하는 아래 셀의 훈련 루프를 살펴보면, 다중 추적에도 불구하고, 생성된 그래프는 사실상 동일하므로 다소 비효율적입니다. However, it's possible that a Python argument is not being used to control graph construction. In these cases, a change in the Python value can trigger needless retracing. Take, for example, this training loop, which AutoGraph will dynamically unroll. Despite the multiple traces, the generated graph is actually identical, so this is a bit inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uydzR5JYUU8H"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0606 18:18:44.085334 28908 tf_logging.py:161] Entity <function train at 0x0000021B770ED510> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: (unicode error) 'utf-8' codec can't decode byte 0xc3 in position 10: invalid continuation byte (tmpivq5sbzp.py, line 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function train at 0x0000021B770ED510> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: (unicode error) 'utf-8' codec can't decode byte 0xc3 in position 10: invalid continuation byte (tmpivq5sbzp.py, line 3)\n",
      "num_steps 추적 = 10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0mexperimental_verbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m         experimental_partial_types=partial_types)\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mto_graph\u001b[1;34m(entity, recursive, arg_values, arg_types, experimental_optional_features, experimental_strip_decorators, experimental_verbose, experimental_partial_types)\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[0msource_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogram_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequired_imports\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m         include_source_map=True)\n\u001b[0m\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\compiler.py\u001b[0m in \u001b[0;36mast_to_object\u001b[1;34m(nodes, indentation, include_source_map, source_prefix, delete_on_exit)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0matexit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m   \u001b[0mcompiled_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_source\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\imp.py\u001b[0m in \u001b[0;36mload_source\u001b[1;34m(name, pathname, file)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m     \u001b[1;31m# To allow reloading to potentially work, use a non-hacked loader which\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36msource_to_code\u001b[1;34m(self, data, path, _optimize)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;31mSyntaxError\u001b[0m: (unicode error) 'utf-8' codec can't decode byte 0xc3 in position 10: invalid continuation byte (tmpivq5sbzp.py, line 3)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fa53f6490bb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtrain_one_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[0minitializer_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    368\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    369\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 370\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_signature\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1313\u001b[1;33m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1314\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1578\u001b[0m           or call_context_key not in self._function_cache.missed):\n\u001b[0;32m   1579\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1580\u001b[1;33m         \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1581\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1582\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   1510\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1511\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1512\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   1513\u001b[0m         self._function_attributes)\n\u001b[0;32m   1514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    692\u001b[0m                                           converted_func)\n\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, IndexedSlices,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    684\u001b[0m                   \u001b[0moptional_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m                   \u001b[0mforce_conversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m               ), args, kwargs)\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;31m# Wrapping around a decorator allows checks like tf_inspect.getargspec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m         ' AutoGraph team. Cause: %s', target_entity, e)\n\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-fa53f6490bb7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(num_steps)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"num_steps 추적 = {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtrain_one_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m       raise TypeError(\n\u001b[1;32m--> 449\u001b[1;33m           \u001b[1;34m\"Tensor objects are only iterable when eager execution is \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m           \"enabled. To iterate over this tensor use tf.map_fn.\")\n\u001b[0;32m    451\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn."
     ]
    }
   ],
   "source": [
    "def train_one_step():\n",
    "  pass\n",
    "\n",
    "@tf.function\n",
    "def train(num_steps):\n",
    "  print(\"num_steps 추적 = {}\".format(num_steps))\n",
    "  for _ in tf.range(num_steps):\n",
    "    train_one_step()\n",
    "\n",
    "train(num_steps=10)\n",
    "train(num_steps=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f6pjnylLUW8P"
   },
   "source": [
    "The simple workaround here is to cast your arguments to Tensors if they do not affect the shape of the generated graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmL8T-w3UYes"
   },
   "outputs": [],
   "source": [
    "train(num_steps=tf.constant(10))\n",
    "train(num_steps=tf.constant(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "129-iRsPS-gY"
   },
   "source": [
    "## Side effects in `tf.function`\n",
    "\n",
    "In general, Python side effects (like printing or mutating objects) only happen during tracing. So how can you reliably trigger side effects from `tf.function`?\n",
    "\n",
    "The general rule of thumb is to only use Python side effects to debug your traces. Otherwise, TensorFlow ops like `tf.Variable.assign`, `tf.print`, and `tf.summary` are the best way to ensure your code will be traced and executed by the TensorFlow runtime with each call. In general using a functional style will yield the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w2sACuZ9TTRk"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  print(\"추적\", x)\n",
    "  tf.print(\"실행\", x)\n",
    "\n",
    "f(1)\n",
    "f(1)\n",
    "f(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1I0dPiqTV8H"
   },
   "source": [
    "If you would like to execute Python code during each invocation of a `tf.function`, `tf.py_function` is an exit hatch. The drawback of `tf.py_function` is that it's not portable or particularly performant, nor does it work well in distributed (multi-GPU, TPU) setups. Also, since `tf.py_function` has to be wired into the graph, it casts all inputs/outputs to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7aJD--9qTWmg"
   },
   "outputs": [],
   "source": [
    "external_list = []\n",
    "\n",
    "def side_effect(x):\n",
    "  print('파이썬 부수 효과')\n",
    "  external_list.append(x)\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "  tf.py_function(side_effect, inp=[x], Tout=[])\n",
    "\n",
    "f(1)\n",
    "f(1)\n",
    "f(1)\n",
    "assert len(external_list) == 3\n",
    "# py_function이 1을 tf.constant(1)로 캐스팅하기 때문에 .numpy()를 호출할 필요가 있습니다.\n",
    "assert external_list[0].numpy() == 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "msTmv-oyUNaf"
   },
   "source": [
    "## Beware of Python state\n",
    "\n",
    "생성자(generators)나 반복자(iterators)와 같은 많은 파이썬 특성들은 상태를 추적하기 위해 파이썬 런타임에 의존합니다. Many Python features, such as generators and iterators, rely on the Python runtime to keep track of state. In general, while these constructs work as expected in Eager mode, many unexpected things can happen inside a `tf.function` due to tracing behavior.\n",
    "\n",
    "한 가지 예를 들자면, 반복자의 상태를 전진시키는 것은 파이썬의 부수 효과이며, 그러므로 오직 추적과정에서 발생합니다. To give one example, advancing iterator state is a Python side effect and therefore only happens during tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNPD4unZUedH"
   },
   "outputs": [],
   "source": [
    "external_var = tf.Variable(0)\n",
    "@tf.function\n",
    "def buggy_consume_next(iterator):\n",
    "  external_var.assign_add(next(iterator))\n",
    "  tf.print(\"외부 변수의 값:\", external_var)\n",
    "\n",
    "iterator = iter([0, 1, 2, 3])\n",
    "buggy_consume_next(iterator)\n",
    "# This reuses the first value from the iterator, rather than consuming the next value.\n",
    "buggy_consume_next(iterator)\n",
    "buggy_consume_next(iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5XMGXMu-Ufjm"
   },
   "source": [
    "If an iterator is generated and consumed entirely within the tf.function, then it should work correctly. However, the entire iterator is probably being traced, which can lead to a giant graph. This may be what you want. But if you're training on an large in-memory dataset represented as a Python list, then this can generate a very large graph, and `tf.function` is unlikely to yield a speedup.\n",
    "\n",
    "If you want to iterate over Python data, the safest way is to wrap it in a tf.data.Dataset and use the `for x in y` idiom. AutoGraph has special support for safely converting `for` loops when `y` is a tensor or tf.data.Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ms7f1o_QUiHE"
   },
   "outputs": [],
   "source": [
    "def measure_graph_size(f, *args):\n",
    "  g = f.get_concrete_function(*args).graph\n",
    "  print(\"{}({}) contains {} nodes in its graph\".format(\n",
    "      f.__name__, ', '.join(map(str, args)), len(g.as_graph_def().node)))\n",
    "\n",
    "@tf.function\n",
    "def train(dataset):\n",
    "  loss = tf.constant(0)\n",
    "  for x, y in dataset:\n",
    "    loss += tf.abs(y - x) # Some dummy computation.\n",
    "  return loss\n",
    "\n",
    "small_data = [(1, 1)] * 2\n",
    "big_data = [(1, 1)] * 10\n",
    "measure_graph_size(train, small_data)\n",
    "measure_graph_size(train, big_data)\n",
    "\n",
    "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
    "    lambda: small_data, (tf.int32, tf.int32)))\n",
    "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
    "    lambda: big_data, (tf.int32, tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGDstsFpWHEI"
   },
   "source": [
    "\n",
    "When wrapping Python/Numpy data in a Dataset, be mindful of `tf.data.Dataset.from_generator` versus ` tf.data.Dataset.from_tensors`. The former will keep the data in Python and fetch it via `tf.py_function` which can have performance implications, whereas the latter will bundle a copy of the data as one large `tf.constant()` node in the graph, which can have memory implications.\n",
    "\n",
    "Reading data from files via TFRecordDataset/CsvDataset/etc. is the most effective way to consume data, as then TensorFlow itself can manage the asynchronous loading and prefetching of data, without having to involve Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRdlnCfV_UTn"
   },
   "source": [
    "## Automatic Control Dependencies\n",
    "\n",
    "A very appealing property of functions as the programming model, over a general dataflow graph, is that functions can give the runtime more information about what was the intended behavior of the code.\n",
    "\n",
    "For example, when writing code which has multiple reads and writes to the same variables, a dataflow graph might not naturally encode the originally intended order of operations. In `tf.function`, we resolve ambiguities in execution order by referring to the execution order of statements in the original Python code. This way, ordering of stateful operations in a `tf.function` replicates the semantics of Eager mode.\n",
    "\n",
    "This means there's no need to add manual control dependencies; `tf.function` is smart enough to add the minimal set of necessary and sufficient control dependencies for your code to run correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SASm0ss8erVX"
   },
   "outputs": [],
   "source": [
    "# Automatic control dependencies\n",
    "\n",
    "a = tf.Variable(1.0)\n",
    "b = tf.Variable(2.0)\n",
    "\n",
    "@tf.function\n",
    "def f(x, y):\n",
    "  a.assign(y * b)\n",
    "  b.assign_add(x * a)\n",
    "  return a + b\n",
    "\n",
    "f(1.0, 2.0)  # 10.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPr_6mK_AQWL"
   },
   "source": [
    "## 변수\n",
    "\n",
    "We can use the same idea of leveraging the intended execution order of the code to make variable creation and utilization very easy in `tf.function`. There is one very important caveat, though, which is that with variables it's possible to write code which behaves differently in eager mode and graph mode.\n",
    "\n",
    "Specifically, this will happen when you create a new Variable with each call. Due to tracing semantics, `tf.function` will reuse the same variable each call, but eager mode will create a new variable with each call. To guard against this mistake, `tf.function` will raise an error if it detects dangerous variable creation behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tx0Vvnb_9OB-"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  v = tf.Variable(1.0)\n",
    "  v.assign_add(x)\n",
    "  return v\n",
    "\n",
    "with assert_raises(ValueError):\n",
    "  f(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKzNjVg8h4ao"
   },
   "outputs": [],
   "source": [
    "# Non-ambiguous code is ok though\n",
    "\n",
    "v = tf.Variable(1.0)\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "  return v.assign_add(x)\n",
    "\n",
    "print(f(1.0))  # 2.0\n",
    "print(f(2.0))  # 4.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQrG5_kOiKl_"
   },
   "outputs": [],
   "source": [
    "# 변수들이 함수가 실행될 때 처음으로 생성되었다는것을 증명할 수 있는한, tf.function안에 변수를 생성할 수 있습니다.\n",
    "# You can also create variables inside a tf.function as long as we can prove that those variables are created only the first time the function is executed.\n",
    "\n",
    "class C: pass\n",
    "obj = C(); obj.v = None\n",
    "\n",
    "@tf.function\n",
    "def g(x):\n",
    "  if obj.v is None:\n",
    "    obj.v = tf.Variable(1.0)\n",
    "  return obj.v.assign_add(x)\n",
    "\n",
    "print(g(1.0))  # 2.0\n",
    "print(g(2.0))  # 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IOVc1eujMH2"
   },
   "outputs": [],
   "source": [
    "# 변수 이니셜라이저는 함수의 매개변수와 다른 변수들의 값에 의존할 수 있습니다. \n",
    "# Variable initializers can depend on function arguments and on values of other\n",
    "# variables. We can figure out the right initialization order using the same\n",
    "# method we use to generate control dependencies.\n",
    "\n",
    "state = []\n",
    "@tf.function\n",
    "def fn(x):\n",
    "  if not state:\n",
    "    state.append(tf.Variable(2.0 * x))\n",
    "    state.append(tf.Variable(state[0] * 3.0))\n",
    "  return state[0] * x * state[1]\n",
    "\n",
    "print(fn(tf.constant(1.0)))\n",
    "print(fn(tf.constant(3.0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5f05Vr_YBUCz"
   },
   "source": [
    "# Using AutoGraph\n",
    "\n",
    "The [autograph](https://www.tensorflow.org/guide/autograph) library is fully integrated with `tf.function`, and it will rewrite conditionals and loops which depend on Tensors to run dynamically in the graph.\n",
    "\n",
    "`tf.cond` and `tf.while_loop` continue to work with `tf.function`, but code with control flow is often easier to write and understand when written in imperative style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yCQTtTPTW3WF"
   },
   "outputs": [],
   "source": [
    "# Simple loop\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "  while tf.reduce_sum(x) > 1:\n",
    "    tf.print(x)\n",
    "    x = tf.tanh(x)\n",
    "  return x\n",
    "\n",
    "f(tf.random.uniform([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlQD1ffRXJhl"
   },
   "outputs": [],
   "source": [
    "# If you're curious you can inspect the code autograph generates.\n",
    "# It feels like reading assembly language, though.\n",
    "\n",
    "def f(x):\n",
    "  while tf.reduce_sum(x) > 1:\n",
    "    tf.print(x)\n",
    "    x = tf.tanh(x)\n",
    "  return x\n",
    "\n",
    "print(tf.autograph.to_code(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgKmkrNTZSyz"
   },
   "source": [
    "## AutoGraph: Conditionals\n",
    "\n",
    "AutoGraph will convert `if` statements into the equivalent `tf.cond` calls.\n",
    "\n",
    "This substitution is made if the condition is a Tensor. Otherwise, the conditional is executed during tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-7KllizZYsy"
   },
   "outputs": [],
   "source": [
    "def test_tf_cond(f, *args):\n",
    "  g = f.get_concrete_function(*args).graph\n",
    "  if any(node.name == 'cond' for node in g.as_graph_def().node):\n",
    "    print(\"{}({}) uses tf.cond.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n",
    "  else:\n",
    "    print(\"{}({}) executes normally.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o86paGR-Zadi"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def hyperparam_cond(x, training=True):\n",
    "  if training:\n",
    "    x = tf.nn.dropout(x, rate=0.5)\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def maybe_tensor_cond(x):\n",
    "  if x < 0:\n",
    "    x = -x\n",
    "  return x\n",
    "\n",
    "test_tf_cond(hyperparam_cond, tf.ones([1], dtype=tf.float32))\n",
    "test_tf_cond(maybe_tensor_cond, tf.constant(-1))\n",
    "test_tf_cond(maybe_tensor_cond, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xFLfdApZh8q"
   },
   "source": [
    "`tf.cond` has a number of subtleties.\n",
    "- it works by tracing both sides of the conditional, and then choosing the appropriate branch at runtime, depending on the condition. Tracing both sides can result in unexpected execution of Python code\n",
    "- it requires that if one branch creates a tensor used downstream, the other branch must also create that tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VTMoZEVaZiwk"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def f():\n",
    "  x = tf.constant(0)\n",
    "  if tf.constant(True):\n",
    "    x = x + 1\n",
    "    print(\"Tracing `then` branch\")\n",
    "  else:\n",
    "    x = x - 1\n",
    "    print(\"Tracing `else` branch\")\n",
    "  return x\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_dxWHeFZlaQ"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def f():\n",
    "  if tf.constant(True):\n",
    "    x = tf.ones([3, 3])\n",
    "  return x\n",
    "\n",
    "# Throws an error because both branches need to define `x`.\n",
    "with assert_raises(ValueError):\n",
    "  f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yho4J0a0ZkQS"
   },
   "source": [
    "## AutoGraph and loops\n",
    "\n",
    "AutoGraph has a few simple rules for converting loops.\n",
    "\n",
    "- `for`: Convert if the iterable is a tensor\n",
    "- `while`: Convert if the while condition depends on a tensor\n",
    "\n",
    "If a loop is converted, it will be dynamically unrolled with `tf.while_loop`, or in the special case of a `for x in tf.data.Dataset`, transformed into `tf.data.Dataset.reduce`.\n",
    "\n",
    "If a loop is _not_ converted, it will be statically unrolled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyzGNQAuZsky"
   },
   "outputs": [],
   "source": [
    "def test_dynamically_unrolled(f, *args):\n",
    "  g = f.get_concrete_function(*args).graph\n",
    "  if any(node.name == 'while' for node in g.as_graph_def().node):\n",
    "    print(\"{}({}) uses tf.while_loop.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n",
    "  elif any(node.name == 'ReduceDataset' for node in g.as_graph_def().node):\n",
    "    print(\"{}({}) uses tf.data.Dataset.reduce.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n",
    "  else:\n",
    "    print(\"{}({}) gets unrolled.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7tmncQTZt6_"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def for_in_range():\n",
    "  x = 0\n",
    "  for i in range(5):\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def for_in_tfrange():\n",
    "  x = tf.constant(0, dtype=tf.int32)\n",
    "  for i in tf.range(5):\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def for_in_tfdataset():\n",
    "  x = tf.constant(0, dtype=tf.int64)\n",
    "  for i in tf.data.Dataset.range(5):\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(for_in_range)\n",
    "test_dynamically_unrolled(for_in_tfrange)\n",
    "test_dynamically_unrolled(for_in_tfdataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l6s7aU-padY5"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def while_py_cond():\n",
    "  x = 5\n",
    "  while x > 0:\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def while_tf_cond():\n",
    "  x = tf.constant(5)\n",
    "  while x > 0:\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(while_py_cond)\n",
    "test_dynamically_unrolled(while_tf_cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSr64Xn6ap-S"
   },
   "source": [
    " If you have a `break` or early `return` clause that depends on a tensor, the top-level condition or iterable should also be a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q-VirD-5avdZ"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def buggy_while_py_true_tf_break(x):\n",
    "  while True:\n",
    "    if tf.equal(x, 0):\n",
    "      break\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def while_tf_true_tf_break(x):\n",
    "  while tf.constant(True):\n",
    "    if tf.equal(x, 0):\n",
    "      break\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "with assert_raises(TypeError):\n",
    "  test_dynamically_unrolled(buggy_while_py_true_tf_break, 5)\n",
    "test_dynamically_unrolled(while_tf_true_tf_break, 5)\n",
    "\n",
    "@tf.function\n",
    "def buggy_py_for_tf_break():\n",
    "  x = 0\n",
    "  for i in range(5):\n",
    "    if tf.equal(i, 3):\n",
    "      break\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def tf_for_tf_break():\n",
    "  x = 0\n",
    "  for i in tf.range(5):\n",
    "    if tf.equal(i, 3):\n",
    "      break\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "with assert_raises(TypeError):\n",
    "  test_dynamically_unrolled(buggy_py_for_tf_break)\n",
    "test_dynamically_unrolled(tf_for_tf_break)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hyksHW9TCukR"
   },
   "source": [
    "In order to accumulate results from a dynamically unrolled loop, you'll want to use `tf.TensorArray`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HJ3Vb3dXfefN"
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 3\n",
    "feature_size = 4\n",
    "\n",
    "def rnn_step(inp, state):\n",
    "  return inp + state\n",
    "\n",
    "@tf.function\n",
    "def dynamic_rnn(rnn_step, input_data, initial_state):\n",
    "  # [batch, time, features] -> [time, batch, features]\n",
    "  input_data = tf.transpose(input_data, [1, 0, 2])\n",
    "  max_seq_len = input_data.shape[0]\n",
    "\n",
    "  states = tf.TensorArray(tf.float32, size=max_seq_len)\n",
    "  state = initial_state\n",
    "  for i in tf.range(max_seq_len):\n",
    "    state = rnn_step(input_data[i], state)\n",
    "    states = states.write(i, state)\n",
    "  return tf.transpose(states.stack(), [1, 0, 2])\n",
    "  \n",
    "dynamic_rnn(rnn_step,\n",
    "            tf.random.uniform([batch_size, seq_len, feature_size]),\n",
    "            tf.zeros([batch_size, feature_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gmLpHY-bkly"
   },
   "source": [
    "As with `tf.cond`, `tf.while_loop` also comes with a number of subtleties.\n",
    "- Since a loop can execute 0 times, all tensors used downstream of the while_loop must be initialized above the loop\n",
    "- The shape/dtypes of all loop variables must stay consistent with each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CocT5RHwblrQ"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def buggy_loop_var_uninitialized():\n",
    "  for i in tf.range(3):\n",
    "    x = i\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def f():\n",
    "  x = tf.constant(0)\n",
    "  for i in tf.range(3):\n",
    "    x = i\n",
    "  return x\n",
    "\n",
    "with assert_raises(ValueError):\n",
    "  buggy_loop_var_uninitialized()\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FSftc9cCbpAo"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def buggy_loop_type_changes():\n",
    "  x = tf.constant(0, dtype=tf.float32)\n",
    "  for i in tf.range(3): # Yields tensors of type tf.int32...\n",
    "    x = i\n",
    "  return x\n",
    "\n",
    "with assert_raises(tf.errors.InvalidArgumentError):\n",
    "  buggy_loop_type_changes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kWF189prbuK0"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def buggy_concat():\n",
    "  x = tf.ones([0, 10])\n",
    "  for i in tf.range(5):\n",
    "    x = tf.concat([x, tf.ones([1, 10])], axis=0)\n",
    "  return x\n",
    "\n",
    "with assert_raises(ValueError):\n",
    "  buggy_concat()\n",
    "  \n",
    "@tf.function\n",
    "def concat_with_padding():\n",
    "  x = tf.zeros([5, 10])\n",
    "  for i in tf.range(5):\n",
    "    x = tf.concat([x[:i], tf.ones([1, 10]), tf.zeros([4-i, 10])], axis=0)\n",
    "    x.set_shape([5, 10])\n",
    "  return x\n",
    "\n",
    "concat_with_padding()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gVO09og4C_b8"
   },
   "source": [
    "## 다음 단계\n",
    "\n",
    "이제 코드에 더욱 빨리 `tf.function`이전의 노트북들을 다시 방문하여 Now revisit the earlier notebooks and try using `tf.function` to speed up your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tf.function",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "14-2CMFfiuCftv7Dk9Mwppnx61KMIgXsa",
     "timestamp": 1549585991091
    },
    {
     "file_id": "1-q8UuWhUUTsYTaUhKtPoKsxhFuuxy8Nl",
     "timestamp": 1549055827266
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
