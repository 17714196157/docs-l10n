{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPpI7RaYoZuE"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "hro2InpHobKk"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U9i2Dsh-ziXr"
   },
   "source": [
    "# Tensors and Operations\n",
    "# テンソルと演算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hndw-YcxoOJK"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/alpha/tutorials/eager/basics\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/ja/r2/tutorials/eager/basics.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/ja/r2/tutorials/eager/basics.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sILUVbHoSgH"
   },
   "source": [
    "This is an introductory TensorFlow tutorial shows how to:\n",
    "これは、下記の手法を示す TensorFlow の入門チュートリアルです。\n",
    "\n",
    "* Import the required package\n",
    "* Create and use tensors\n",
    "* Use GPU acceleration\n",
    "* Demonstrate `tf.data.Dataset`\n",
    "\n",
    "* 必要なパッケージのインポート\n",
    "* テンソルの作成と使用\n",
    "* GPUの使用\n",
    "* `tf.data.Dataset`のデモ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "miTaGiqV9RjO"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "!pip install tensorflow-gpu==2.0.0-alpha0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1JcS5iBXMRO"
   },
   "source": [
    "## Import TensorFlow\n",
    "## TensorFlowのインポート\n",
    "\n",
    "To get started, import the `tensorflow` module. As of TensorFlow 2.0, eager execution is turned on by default. This enables a more interactive frontend to TensorFlow, the details of which we will discuss much later.\n",
    "\n",
    "はじめに、`tensorflow`モジュールをインポートします。TensorFlow 2.0 では、eager execution が既定でオンとなっています。\n",
    "これにより、TensorFlowのフロントエンドがよりインタラクティブになります。詳細は後述します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjBPmYjLdFmk"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H9UySOPLXdaw"
   },
   "source": [
    "## Tensors\n",
    "## テンソル\n",
    "\n",
    "A Tensor is a multi-dimensional array. Similar to NumPy `ndarray` objects, `tf.Tensor` objects have a data type and a shape. Additionally, `tf.Tensor`s can reside in accelerator memory (like a GPU). TensorFlow offers a rich library of operations ([tf.add](https://www.tensorflow.org/api_docs/python/tf/add), [tf.matmul](https://www.tensorflow.org/api_docs/python/tf/matmul), [tf.linalg.inv](https://www.tensorflow.org/api_docs/python/tf/linalg/inv) etc.) that consume and produce `tf.Tensor`s. These operations automatically convert native Python types, for example:\n",
    "\n",
    "テンソルは多次元配列です。NumPyの`ndarray`オブジェクトと同様に、`tf.Tensor`にはデータ型と形状があります。これに加えて、`tf.Tensor`は（GPUのような）アクセラレータのメモリに置くことができます。TensorFlowには、`tf.Tensor`を使用し生成するたくさんの演算([tf.add](https://www.tensorflow.org/api_docs/python/tf/add), [tf.matmul](https://www.tensorflow.org/api_docs/python/tf/matmul), [tf.linalg.inv](https://www.tensorflow.org/api_docs/python/tf/linalg/inv) 等)ライブラリが存在します。これらの演算では、ネイティブなPythonデータ型が自動変換されます。例を示します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "ngUe237Wt48W"
   },
   "outputs": [],
   "source": [
    "print(tf.add(1, 2))\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "\n",
    "# Operator overloading is also supported\n",
    "print(tf.square(2) + tf.square(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IDY4WsYRhP81"
   },
   "source": [
    "Each `tf.Tensor` has a shape and a datatype:\n",
    "\n",
    "それぞれの`tf.Tensor`には、形状とデータ型があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srYWH1MdJNG7"
   },
   "outputs": [],
   "source": [
    "x = tf.matmul([[1]], [[2, 3]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eBPw8e8vrsom"
   },
   "source": [
    "The most obvious differences between NumPy arrays and `tf.Tensor`s are:\n",
    "\n",
    "NumPy配列と`tf.Tensor`の間の最も明確な違いは\n",
    "\n",
    "1. Tensors can be backed by accelerator memory (like GPU, TPU).\n",
    "2. Tensors are immutable.\n",
    "\n",
    "1. テンソルは（GPUやTPUなどの）アクセラレータメモリを使用できる\n",
    "2. テンソルは変更不可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dwi1tdW3JBw6"
   },
   "source": [
    "### NumPy Compatibility\n",
    "### NumPy互換性\n",
    "\n",
    "Converting between a TensorFlow `tf.Tensor`s and a NumPy `ndarray` is easy:\n",
    "\n",
    "TensorFlow の`tf.Tensor`と NumPy の`ndarray`間の変換は簡単です。\n",
    "\n",
    "* TensorFlow operations automatically convert NumPy ndarrays to Tensors.\n",
    "* NumPy operations automatically convert Tensors to NumPy ndarrays.\n",
    "\n",
    "* TensorFlowの演算によりNumPyのndarrayは自動的にテンソルに変換される\n",
    "* NumPyの演算によりテンソルは自動的にNuｍPyのndarrayに変換される\n",
    "\n",
    "Tensors are explicitly converted to NumPy ndarrays using their `.numpy()` method. These conversions are typically cheap since the array and `tf.Tensor` share the underlying memory representation, if possible. However, sharing the underlying representation isn't always possible since the `tf.Tensor` may be hosted in GPU memory while NumPy arrays are always backed by host memory, and the conversion involves a copy from GPU to host memory.\n",
    "\n",
    "テンソルは`.numpy()`メソッドを使って明示的にNumPyのndarrayに変換されます。NumPyのndarrayと`tf.Tensor`はできるだけ下層の表現を共通化されているので、通常この変換のコストは小さいです。しかし、NumPy入れるはホスト側のメモリに置かれる一方、`tf.Tensor`はGPUのメモリに置かれる可能性もあるため、下層の表現をいつも共通化できるとは限りません。また、変換にはGPUからホスト側メモリへのコピーも関わってきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCUWzso6mbqR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n",
    "print(\"TensorFlow演算によりnumpy配列は自動的にテンソルに変換される\")\n",
    "tensor = tf.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "print(\"And NumPy operations convert Tensors to numpy arrays automatically\")\n",
    "print(\"またNumPy演算によりテンソルは自動的にnumpy配列に変換される\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
    "print(\".numpy()メソッドによりテンソルは明示的にnumpy配列に変換される\")\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PBNP8yTRfu_X"
   },
   "source": [
    "## GPU acceleration\n",
    "## GPUによる高速化\n",
    "\n",
    "Many TensorFlow operations are accelerated using the GPU for computation. Without any annotations, TensorFlow automatically decides whether to use the GPU or CPU for an operation—copying the tensor between CPU and GPU memory, if necessary. Tensors produced by an operation are typically backed by the memory of the device on which the operation executed, for example:\n",
    "\n",
    "TensorFlowの演算の多くは、GPUを計算に使用することで高速化されます。TensorFlowは演算に注釈をつけなくとも、自動的にGPUとCPUのどちらかを選択し、必要であればテンソルをGPUメモリとCPUメモリの間でコピーして実行します。演算で生成されたテンソルは通常演算を実行したデバイスのメモリに置かれます。例を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "3Twf_Rw-gQFM"
   },
   "outputs": [],
   "source": [
    "x = tf.random.uniform([3, 3])\n",
    "\n",
    "print(\"Is there a GPU available: \"),\n",
    "print(\"利用できるGPUはあるか: \"),\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "print(\"Is the Tensor on GPU #0:  \"),\n",
    "print(\"テンソルはGPU #0にあるか:  \"),\n",
    "print(x.device.endswith('GPU:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vpgYzgVXW2Ud"
   },
   "source": [
    "### Device Names\n",
    "### デバイス名\n",
    "\n",
    "The `Tensor.device` property provides a fully qualified string name of the device hosting the contents of the tensor. This name encodes many details, such as an identifier of the network address of the host on which this program is executing and the device within that host. This is required for distributed execution of a TensorFlow program. The string ends with `GPU:<N>` if the tensor is placed on the `N`-th GPU on the host.\n",
    "\n",
    "`Tensor.device`プロパティにより、そのテンソルの内容を保持しているデバイスの完全な名前文字列を得ることができます。この名前には、プログラムを実行中のホストのネットワークアドレスや、ホスト上のデバイスについての詳細がエンコードされています。この情報は、TensorFlowプログラムの分散実行に必要なものです。テンソルがホスト上の`N`番目のGPUにある場合、文字列の最後は`GPU:<N>`となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZWZQCimzuqyP"
   },
   "source": [
    "### Explicit Device Placement\n",
    "### 明示的デバイス配置\n",
    "\n",
    "In TensorFlow, *placement* refers to how individual operations are assigned (placed on) a device for execution. As mentioned, when there is no explicit guidance provided, TensorFlow automatically decides which device to execute an operation and copies tensors to that device, if needed. However, TensorFlow operations can be explicitly placed on specific devices using the `tf.device` context manager, for example:\n",
    "\n",
    "TensorFlowでいう**配置**は、個々の演算を実行するためにどのようにデバイスにアサイン（配置）されるかを指します。前述の通り、明示的な示唆がなければ、TensorFlowは演算を実行するデバイスを自動的に決め、必要であればテンソルをそのデバイスにコピーします。しかし、`tf.device`コンテキストマネジャーを使うことで、TensorFlowの演算を特定のデバイスに配置することができます。例を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RjkNZTuauy-Q"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def time_matmul(x):\n",
    "  start = time.time()\n",
    "  for loop in range(10):\n",
    "    tf.matmul(x, x)\n",
    "\n",
    "  result = time.time()-start\n",
    "    \n",
    "  print(\"10 loops: {:0.2f}ms\".format(1000*result))\n",
    "\n",
    "# Force execution on CPU\n",
    "# CPUでの実行を強制\n",
    "print(\"On CPU:\")\n",
    "with tf.device(\"CPU:0\"):\n",
    "  x = tf.random.uniform([1000, 1000])\n",
    "  assert x.device.endswith(\"CPU:0\")\n",
    "  time_matmul(x)\n",
    "\n",
    "# Force execution on GPU #0 if available\n",
    "# GPU #0があればその上での実行を強制\n",
    "if tf.test.is_gpu_available():\n",
    "  print(\"On GPU:\")\n",
    "  with tf.device(\"GPU:0\"): # 2番めのGPUなら GPU:1, 3番目なら GPU:2 など\n",
    "    x = tf.random.uniform([1000, 1000])\n",
    "    assert x.device.endswith(\"GPU:0\")\n",
    "    time_matmul(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1K4dlhhHtQj"
   },
   "source": [
    "## Datasets\n",
    "## データセット\n",
    "\n",
    "This section uses the [`tf.data.Dataset` API](https://www.tensorflow.org/guide/datasets) to build a pipeline for feeding data to your model. The `tf.data.Dataset` API is used to build performant, complex input pipelines from simple, re-usable pieces that will feed your model's training or evaluation loops.\n",
    "\n",
    "このセクションでは[`tf.data.Dataset` API](https://www.tensorflow.org/guide/datasets)を使って、モデルにデータを供給するためのパイプラインを構築します。`tf.data.Dataset` APIは、単純で再利用可能な部品をもとに、モデルの訓練あるいは評価ループにデータを供給する高性能で複雑な入力パイプラインを構築するために使われます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zI0fmOynH-Ne"
   },
   "source": [
    "### Create a source `Dataset`\n",
    "### ソース`Dataset`の作成\n",
    "\n",
    "\n",
    "Create a *source* dataset using one of the factory functions like [`Dataset.from_tensors`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensors), [`Dataset.from_tensor_slices`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices), or using objects that read from files like [`TextLineDataset`](https://www.tensorflow.org/api_docs/python/tf/data/TextLineDataset) or [`TFRecordDataset`](https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset). See the [TensorFlow Dataset guide](https://www.tensorflow.org/guide/datasets#reading_input_data) for more information.\n",
    "\n",
    "[`Dataset.from_tensors`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensors)や[`Dataset.from_tensor_slices`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices)といったファクトリー関数または[`TextLineDataset`](https://www.tensorflow.org/api_docs/python/tf/data/TextLineDataset) あるいは[`TFRecordDataset`](https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset)のようなファイルを読み込むオブジェクトを使って、 **元となる**データセットを作成しましょう。詳しくは、[TensorFlow Dataset guide](https://www.tensorflow.org/guide/datasets#reading_input_data)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F04fVOHQIBiG"
   },
   "outputs": [],
   "source": [
    "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Create a CSV file\n",
    "# CSVファイルを作成\n",
    "import tempfile\n",
    "_, filename = tempfile.mkstemp()\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "  f.write(\"\"\"Line 1\n",
    "Line 2\n",
    "Line 3\n",
    "  \"\"\")\n",
    "\n",
    "ds_file = tf.data.TextLineDataset(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vbxIhC-5IPdf"
   },
   "source": [
    "### Apply transformations\n",
    "### 変換の適用\n",
    "\n",
    "Use the transformations functions like [`map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map), [`batch`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch), and [`shuffle`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle) to apply transformations to dataset records.\n",
    "\n",
    "[`map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map), [`batch`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch), [`shuffle`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle)などの変換関数を使って、データセットレコードに変換を適用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXSDZWE-ISsd"
   },
   "outputs": [],
   "source": [
    "ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n",
    "\n",
    "ds_file = ds_file.batch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A8X1GNfoIZKJ"
   },
   "source": [
    "### Iterate\n",
    "### イテレーション\n",
    "\n",
    "`tf.data.Dataset` objects support iteration to loop over records:\n",
    "\n",
    "`tf.data.Dataset`オブジェクトは、中のレコードを繰り返し利用するためのイテレーションをサポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ws-WKRk5Ic6-"
   },
   "outputs": [],
   "source": [
    "print('Elements of ds_tensors:')\n",
    "for x in ds_tensors:\n",
    "  print(x)\n",
    "\n",
    "print('\\nElements in ds_file:')\n",
    "for x in ds_file:\n",
    "  print(x)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "name": "basics.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
