{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DweYe9FcbMK_"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "AVV2e0XKbJeX"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sUtoed20cRJJ"
   },
   "source": [
    "# Load CSV with tf.data\n",
    "# tf.data を使って CSV をロードする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ap_W4aQcgNT"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/alpha/tutorials/load_data/text\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/じja/r2/tutorials/load_data/csv.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/ja/r2/tutorials/load_data/csv.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-3Xbt0FfGfs"
   },
   "source": [
    "This tutorial provides an example of how to load CSV data from a file into a `tf.data.Dataset`.\n",
    "\n",
    "このチュートリアルでは、CSV データをどうやってファイルから `tf.data.Dataset` にロードするかの例を示します。\n",
    "\n",
    "The data used in this tutorial are taken from the Titanic passenger list. We'll try to predict the likelihood a passenger survived based on characteristics like age, gender, ticket class, and whether the person was traveling alone.\n",
    "\n",
    "このチュートリアルで使われているデータはタイタニック号の乗客リストから取られたものです。乗客が生き残る可能性を、年齢、性別、チケットの等級、そして乗客が一人で旅行しているか否かといった特性から予測することを試みます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgZ9gjmPfSnK"
   },
   "source": [
    "## Setup\n",
    "## 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I4dwMQVQMQWD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.0.0-alpha0 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (2.0.0a0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.16.2)\n",
      "Requirement already satisfied: gast>=0.2.0 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (0.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (0.33.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (0.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.0.9)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.19.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.0.7)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (0.7.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.12.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.2 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (0.1.4)\n",
      "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.14.0a20190301)\n",
      "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.14.0.dev2019030115)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (3.7.0)\n",
      "Requirement already satisfied: h5py in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (2.9.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.0.1)\n",
      "Requirement already satisfied: setuptools in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0) (39.0.1)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.0.0-alpha0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tfds-nightly\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/ab/9a022fec0e6640cbb776abb20a6ba7374b70d97bb75b997c15e588113e70/tfds_nightly-1.0.2.dev201906030105-py3-none-any.whl (830kB)\n",
      "\u001b[K    100% |████████████████████████████████| 839kB 10.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: promise in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tfds-nightly) (2.2.1)\n",
      "Requirement already satisfied: wrapt in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tfds-nightly) (1.11.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tfds-nightly) (3.7.0)\n",
      "Collecting dill (from tfds-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/42/bfe2e0857bc284cbe6a011d93f2a9ad58a22cb894461b199ae72cfef0f29/dill-0.2.9.tar.gz (150kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 13.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tfds-nightly) (1.1.0)\n",
      "Requirement already satisfied: future in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tfds-nightly) (0.17.1)\n",
      "Requirement already satisfied: six in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tfds-nightly) (1.12.0)\n",
      "Collecting psutil (from tfds-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/c1/beed5e4eaa1345901b595048fab1c85aee647ea0fc02d9e8bf9aceb81078/psutil-5.6.2.tar.gz (432kB)\n",
      "\u001b[K    100% |████████████████████████████████| 440kB 15.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tfds-nightly) (1.16.2)\n",
      "Requirement already satisfied: tensorflow-metadata in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tfds-nightly) (0.13.0)\n",
      "Requirement already satisfied: tqdm in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tfds-nightly) (4.31.1)\n",
      "Requirement already satisfied: requests in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tfds-nightly) (2.21.0)\n",
      "Requirement already satisfied: absl-py in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tfds-nightly) (0.7.0)\n",
      "Requirement already satisfied: setuptools in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from protobuf>=3.6.1->tfds-nightly) (39.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from tensorflow-metadata->tfds-nightly) (1.5.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from requests->tfds-nightly) (2019.3.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from requests->tfds-nightly) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from requests->tfds-nightly) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/masatoshi/pyenvs/tf2/lib/python3.6/site-packages (from requests->tfds-nightly) (2.8)\n",
      "Building wheels for collected packages: dill, psutil\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/masatoshi/Library/Caches/pip/wheels/5b/d7/0f/e58eae695403de585269f4e4a94e0cd6ca60ec0c202936fa4a\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/masatoshi/Library/Caches/pip/wheels/17/08/ec/22b464874958c3fc91e1a75748fae2220eb704a8b1035f9a03\n",
      "Successfully built dill psutil\n",
      "Installing collected packages: dill, psutil, tfds-nightly\n",
      "Successfully installed dill-0.2.9 psutil-5.6.2 tfds-nightly-1.0.2.dev201906030105\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tfds-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baYFZMW_bJHh"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ncf5t6tgL5ZI"
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
    "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
    "\n",
    "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
    "test_file_path = tf.keras.utils.get_file(\"eval.csv\", TEST_DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ONE94qulk6S"
   },
   "outputs": [],
   "source": [
    "# Make numpy values easier to read.\n",
    "# numpy の値を読みやすくする\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wuqj601Qw0Ml"
   },
   "source": [
    "## Load data\n",
    "## データのロード\n",
    "\n",
    "So we know what we're doing, lets look at the top of the CSV file we're working with.\n",
    "\n",
    "何をしているかはわかっていますが、扱っている CSV ファイルの先頭を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54Dv7mCrf9Yw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone\n",
      "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n",
      "1,female,38.0,1,0,71.2833,First,C,Cherbourg,n\n",
      "1,female,26.0,0,0,7.925,Third,unknown,Southampton,y\n",
      "1,female,35.0,1,0,53.1,First,C,Southampton,n\n",
      "0,male,28.0,0,0,8.4583,Third,unknown,Queenstown,y\n",
      "0,male,2.0,3,1,21.075,Third,unknown,Southampton,n\n",
      "1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n\n",
      "1,female,14.0,1,0,30.0708,Second,unknown,Cherbourg,n\n",
      "1,female,4.0,1,1,16.7,Third,G,Southampton,n\n"
     ]
    }
   ],
   "source": [
    "!head {train_file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOYKQKmMj3D6"
   },
   "source": [
    "As you can see, the columns in the CSV are labeled. We need the list later on, so let's read it out of the file.\n",
    "\n",
    "ご覧のように、CSV の列にはラベルが付いています。後ほど必要になるので、ファイルから読み出しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0sLG216MtwT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n"
     ]
    }
   ],
   "source": [
    "# CSV columns in the input file.\n",
    "# 入力ファイル中の CSV 列\n",
    "with open(train_file_path, 'r') as f:\n",
    "    names_row = f.readline()\n",
    "\n",
    "\n",
    "CSV_COLUMNS = names_row.rstrip('\\n').split(',')\n",
    "print(CSV_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZS-bt1LvWn2x"
   },
   "source": [
    " The dataset constructor will pick these labels up automatically.\n",
    " \n",
    " データセットコンストラクタはこれらのラベルを自動的にピックアップします。\n",
    "\n",
    "If the file you are working with does not contain the column names in the first line, pass them in a list of strings to  the `column_names` argument in the `make_csv_dataset` function.\n",
    "\n",
    "使用するファイルの1行目にコラム名がない場合、`make_csv_dataset` 関数の `column_names` 引数に文字列のリストとして渡します。\n",
    "\n",
    "```python\n",
    "\n",
    "CSV_COLUMNS = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
    "\n",
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "     ...,\n",
    "     column_names=CSV_COLUMNS,\n",
    "     ...)\n",
    "  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZfhoX7bR9u4"
   },
   "source": [
    "This example is going to use all the available columns. If you need to omit some columns from the dataset, create a list of just the columns you plan to use, and pass it into the (optional) `select_columns` argument of the constructor.\n",
    "\n",
    "この例では使用可能な列をすべて使うことになります。データセットから列を除く必要がある場合には、使用したい列だけを含むリストを作り、コンストラクタの（オプションである）`select_columns` 引数として渡します。\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "drop_columns = ['fare', 'embark_town']\n",
    "columns_to_use = [col for col in CSV_COLUMNS if col not in drop_columns]\n",
    "\n",
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "  ...,\n",
    "  select_columns = columns_to_use, \n",
    "  ...)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67mfwr4v-mN_"
   },
   "source": [
    "We also have to identify which column will serve as the labels for each example, and what those labels are.\n",
    "\n",
    "各サンプルのラベルとなる列を特定し、それが何であるかを示す必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iXROZm5f3V4E"
   },
   "outputs": [],
   "source": [
    "LABELS = [0, 1]\n",
    "LABEL_COLUMN = 'survived'\n",
    "\n",
    "FEATURE_COLUMNS = [column for column in CSV_COLUMNS if column != LABEL_COLUMN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4N-plO4tDXd"
   },
   "source": [
    "Now that these constructor argument values are in place,  read the CSV data from the file and create a dataset. \n",
    "\n",
    "コンストラクタの引数の値が揃ったので、ファイルから CSV データを読み込みデータセットを作ることにしましょう。\n",
    "\n",
    "(For the full documentation, see `tf.data.experimental.make_csv_dataset`)\n",
    "\n",
    "（完全なドキュメントは、`tf.data.experimental.make_csv_dataset` を参照してください）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Co7UJ7gpNADC"
   },
   "outputs": [],
   "source": [
    "def get_dataset(file_path):\n",
    "  dataset = tf.data.experimental.make_csv_dataset(\n",
    "      file_path,\n",
    "      batch_size=12, # Artificially small to make examples easier to show.\n",
    "      label_name=LABEL_COLUMN,\n",
    "      na_value=\"?\",\n",
    "      num_epochs=1,\n",
    "      ignore_errors=True)\n",
    "  return dataset\n",
    "\n",
    "raw_train_data = get_dataset(train_file_path)\n",
    "raw_test_data = get_dataset(test_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHUQFKoQI6G7"
   },
   "source": [
    "Each item in the dataset is a batch, represented as a tuple of (*many examples*, *many labels*). The data from the examples is organized in column-based tensors (rather than row-based tensors), each with as many elements as the batch size (12 in this case).\n",
    "\n",
    "データセットを構成する要素は、(複数のサンプル, 複数のラベル)の形のタプルとして表されるバッチです。サンプル中のデータは（行ベースのテンソルではなく）列ベースのテンソルとして構成され、それぞれはバッチサイズ（このケースでは12個）の要素が含まれます。\n",
    "\n",
    "It might help to see this yourself.\n",
    "\n",
    "実際に見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWtFYtwXIeuj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLES: \n",
      " OrderedDict([('sex', <tf.Tensor: id=169, shape=(12,), dtype=string, numpy=\n",
      "array([b'female', b'female', b'male', b'male', b'male', b'female',\n",
      "       b'male', b'female', b'male', b'male', b'male', b'female'],\n",
      "      dtype=object)>), ('age', <tf.Tensor: id=161, shape=(12,), dtype=float32, numpy=\n",
      "array([15. , 34. , 21. , 18. , 55.5, 31. , 18. , 33. , 36. , 40. , 47. ,\n",
      "       25. ], dtype=float32)>), ('n_siblings_spouses', <tf.Tensor: id=167, shape=(12,), dtype=int32, numpy=array([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1], dtype=int32)>), ('parch', <tf.Tensor: id=168, shape=(12,), dtype=int32, numpy=array([0, 1, 0, 0, 0, 0, 0, 2, 0, 4, 0, 1], dtype=int32)>), ('fare', <tf.Tensor: id=166, shape=(12,), dtype=float32, numpy=\n",
      "array([  7.225,  32.5  ,   8.663,  73.5  ,   8.05 , 113.275,   7.75 ,\n",
      "        27.75 ,  78.85 ,  27.9  ,   9.   ,  30.   ], dtype=float32)>), ('class', <tf.Tensor: id=163, shape=(12,), dtype=string, numpy=\n",
      "array([b'Third', b'Second', b'Third', b'Second', b'Third', b'First',\n",
      "       b'Third', b'Second', b'First', b'Third', b'Third', b'Second'],\n",
      "      dtype=object)>), ('deck', <tf.Tensor: id=164, shape=(12,), dtype=string, numpy=\n",
      "array([b'unknown', b'unknown', b'unknown', b'unknown', b'unknown', b'D',\n",
      "       b'unknown', b'unknown', b'C', b'unknown', b'unknown', b'unknown'],\n",
      "      dtype=object)>), ('embark_town', <tf.Tensor: id=165, shape=(12,), dtype=string, numpy=\n",
      "array([b'Cherbourg', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Southampton', b'Cherbourg', b'Southampton', b'Southampton',\n",
      "       b'Southampton', b'Southampton', b'Southampton', b'Southampton'],\n",
      "      dtype=object)>), ('alone', <tf.Tensor: id=162, shape=(12,), dtype=string, numpy=\n",
      "array([b'y', b'n', b'y', b'y', b'y', b'n', b'y', b'n', b'n', b'n', b'y',\n",
      "       b'n'], dtype=object)>)]) \n",
      "\n",
      "LABELS: \n",
      " tf.Tensor([1 1 0 0 0 1 0 1 0 0 0 1], shape=(12,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "examples, labels = next(iter(raw_train_data)) # Just the first batch.\n",
    "print(\"EXAMPLES: \\n\", examples, \"\\n\")\n",
    "print(\"LABELS: \\n\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9cryz31lxs3e"
   },
   "source": [
    "## Data preprocessing\n",
    "## データ処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tSyrkSQwYHKi"
   },
   "source": [
    "### Categorical data\n",
    "### カテゴリデータ\n",
    "\n",
    "Some of the columns in the CSV data are categorical columns. That is, the content should be one of a limited set of options.\n",
    "\n",
    "この CSV データ中のいくつかの列はカテゴリ列です。つまり、その中身は、限られた選択肢の中のひとつである必要があります。\n",
    "\n",
    "In the CSV, these options are represented as text. This text needs to be converted to numbers before the model can be trained. To facilitate that, we need to create a list of categorical columns, along with a list of the options available in each column.\n",
    "\n",
    "この CSV では、これらの選択肢はテキストとして表現されています。このテキストは、モデルの訓練を行えるように、数字に変換する必要があります。これをやりやすくするため、カテゴリ列のリストとその選択肢のリストを作成する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mWDniduKMw-C"
   },
   "outputs": [],
   "source": [
    "CATEGORIES = {\n",
    "    'sex': ['male', 'female'],\n",
    "    'class' : ['First', 'Second', 'Third'],\n",
    "    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
    "    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
    "    'alone' : ['y', 'n']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Ii0YWsoKBVx"
   },
   "source": [
    "Write a function that takes a tensor of categorical values, matches it to a list of value names, and then performs a one-hot encoding.\n",
    "\n",
    "カテゴリ値のテンソルを受け取り、それを値の名前のリストとマッチングして、さらにワンホット・エンコーディングを行う関数を書きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bP02_BflkDbv"
   },
   "outputs": [],
   "source": [
    "def process_categorical_data(data, categories):\n",
    "  \"\"\"Returns a one-hot encoded tensor representing categorical values.\"\"\"\n",
    "  \"\"\"カテゴリ値を表すワンホット・エンコーディングされたテンソルを返す\"\"\"\n",
    "  \n",
    "  # Remove leading ' '.\n",
    "  # 最初の ' ' を取り除く\n",
    "  data = tf.strings.regex_replace(data, '^ ', '')\n",
    "  # Remove trailing '.'.\n",
    "  # 最後の '.' を取り除く\n",
    "  data = tf.strings.regex_replace(data, r'\\.$', '')\n",
    "  \n",
    "  # ONE HOT ENCODE\n",
    "  # ワンホット・エンコーディング\n",
    "  # Reshape data from 1d (a list) to a 2d (a list of one-element lists)\n",
    "  # data を1次元（リスト）から2次元（要素が1個のリストのリスト）にリシェープ\n",
    "  data = tf.reshape(data, [-1, 1])\n",
    "  # For each element, create a new list of boolean values the length of categories,\n",
    "  # where the truth value is element == category label\n",
    "  # それぞれの要素について、カテゴリ数の長さの真偽値のリストで、\n",
    "  # 真は要素がカテゴリラベルに一致していることを示すを作成\n",
    "  data = tf.equal(categories, data)\n",
    "  # Cast booleans to floats.\n",
    "  # 真偽値を浮動小数点数にキャスト\n",
    "  data = tf.cast(data, tf.float32)\n",
    "  \n",
    "  # The entire encoding can fit on one line:\n",
    "  # data = tf.cast(tf.equal(categories, tf.reshape(data, [-1, 1])), tf.float32)\n",
    "  # エンコーディング全体を次の1行に収めることもできる：\n",
    "  # data = tf.cast(tf.equal(categories, tf.reshape(data, [-1, 1])), tf.float32)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "To2qbBGGMO1D"
   },
   "source": [
    "To help you visualize this, we'll take a single category-column tensor from the first batch, preprocess it, and show the before and after state.\n",
    "\n",
    "これを可視化するため、最初のバッチからカテゴリ列のレンソル1つを取り出し、処理を行い、前後の状態を示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ds7MOLMkK2Gf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=163, shape=(12,), dtype=string, numpy=\n",
       "array([b'Third', b'Second', b'Third', b'Second', b'Third', b'First',\n",
       "       b'Third', b'Second', b'First', b'Third', b'Third', b'Second'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_tensor = examples['class']\n",
    "class_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HdDUSgpoTKfA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First', 'Second', 'Third']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_categories = CATEGORIES['class']\n",
    "class_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yHQeR47_ObpT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=188, shape=(12, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_class = process_categorical_data(class_tensor, class_categories)\n",
    "processed_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ACkc_cCaTuos"
   },
   "source": [
    "Notice the relationship between the lengths of the two inputs and the shape of the output.\n",
    "\n",
    "2つの入力の長さと、出力の形状の関係に注目してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvvXM8m0T00O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of batch:  12\n",
      "Number of category labels:  3\n",
      "Shape of one-hot encoded tensor:  (12, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of batch: \", len(class_tensor.numpy()))\n",
    "print(\"Number of category labels: \", len(class_categories))\n",
    "print(\"Shape of one-hot encoded tensor: \", processed_class.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9AsbaFmCeJtF"
   },
   "source": [
    "### Continuous data\n",
    "### 連続データ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2maE8d2ijsq"
   },
   "source": [
    "Continuous data needs to be normalized, so that the values fall between 0 and 1. To do that, write a function that multiplies each value by 1 over twice the mean of the column values.\n",
    "\n",
    "連続データは値が0と1の間にになるように標準化する必要があります。これを行うために、それぞれの値を、1を列値の平均の2倍で割ったものをかける関数を書きます。\n",
    "\n",
    "The function should also reshape the data into a two dimensional tensor.\n",
    "\n",
    "この関数は、データの2次元のテンソルへのリシェープも行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwGOy61lkQw-"
   },
   "outputs": [],
   "source": [
    "def process_continuous_data(data, mean):\n",
    "  # Normalize data\n",
    "  # data の標準化\n",
    "  data = tf.cast(data, tf.float32) * 1/(2*mean)\n",
    "  return tf.reshape(data, [-1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Yh8R7BujTAu"
   },
   "source": [
    "To do this calculation, you need the column means. You would obviously need to compute these in real life, but for this example we'll just provide them.\n",
    "\n",
    "この計算を行うためには、列値の平均が必要です。現実には、この値を計算する必要があるのは明らかですが、この例のために値を示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iNE_mTJqegGQ"
   },
   "outputs": [],
   "source": [
    "MEANS = {\n",
    "    'age' : 29.631308,\n",
    "    'n_siblings_spouses' : 0.545455,\n",
    "    'parch' : 0.379585,\n",
    "    'fare' : 34.385399\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "raZtRlmaj-A5"
   },
   "source": [
    "Again, to see what this function is actually doing, we'll take a single tensor of continuous data and show it before and after processing.\n",
    "\n",
    "前と同様に、この関数が実際に何をしているかを見るため、連続値のテンソルを1つ取り、処理前と処理後を見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-t_RSBrM2Vm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=161, shape=(12,), dtype=float32, numpy=\n",
       "array([15. , 34. , 21. , 18. , 55.5, 31. , 18. , 33. , 36. , 40. , 47. ,\n",
       "       25. ], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_tensor = examples['age']\n",
    "age_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9lMLaEsjq3K"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=197, shape=(12, 1), dtype=float32, numpy=\n",
       "array([[0.253],\n",
       "       [0.574],\n",
       "       [0.354],\n",
       "       [0.304],\n",
       "       [0.937],\n",
       "       [0.523],\n",
       "       [0.304],\n",
       "       [0.557],\n",
       "       [0.607],\n",
       "       [0.675],\n",
       "       [0.793],\n",
       "       [0.422]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_continuous_data(age_tensor, MEANS['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kPWkC4_1l3IG"
   },
   "source": [
    "### Preprocess the data\n",
    "### データの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jIvyqVAXmsN4"
   },
   "source": [
    "Now assemble these preprocessing tasks into a single function that can be mapped to each batch in the dataset. \n",
    "\n",
    "これらの前処理のタスクを1つの関数にまとめ、データセット内のバッチにマッピングできるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMxEHN0SNPkC"
   },
   "outputs": [],
   "source": [
    "def preprocess(features, labels):\n",
    "  \n",
    "  # Process categorial features.\n",
    "  # カテゴリ特徴量の処理\n",
    "  for feature in CATEGORIES.keys():\n",
    "    features[feature] = process_categorical_data(features[feature],\n",
    "                                                 CATEGORIES[feature])\n",
    "\n",
    "  # Process continuous features.\n",
    "  # 連続特徴量の処理\n",
    "  for feature in MEANS.keys():\n",
    "    features[feature] = process_continuous_data(features[feature],\n",
    "                                                MEANS[feature])\n",
    "  \n",
    "  # Assemble features into a single tensor.\n",
    "  # 特徴量を1つのテンソルに組み立てる\n",
    "  features = tf.concat([features[column] for column in FEATURE_COLUMNS], 1)\n",
    "  \n",
    "  return features, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "34K5ESbYnkg4"
   },
   "source": [
    "Now apply that function with `tf.Dataset.map`, and shuffle the dataset to avoid overfitting.\n",
    "\n",
    "次に、 `tf.Dataset.map` 関数を使って適用し、過学習を防ぐためにデータセットをシャッフルします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7M5km0f_1pVp"
   },
   "outputs": [],
   "source": [
    "train_data = raw_train_data.map(preprocess).shuffle(500)\n",
    "test_data = raw_test_data.map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQOWatzRr2aF"
   },
   "source": [
    "And let's see what a single example looks like.\n",
    "\n",
    "サンプル1個がどうなっているか見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gc1o9ZpCsGGM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=363, shape=(12, 24), dtype=float32, numpy=\n",
       " array([[0.   , 1.   , 0.152, 1.833, 2.634, 0.5  , 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 1.   ],\n",
       "        [1.   , 0.   , 0.607, 0.   , 0.   , 0.153, 0.   , 1.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [0.   , 1.   , 0.371, 0.   , 0.   , 0.153, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [1.   , 0.   , 0.456, 0.   , 0.   , 1.116, 1.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 1.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 1.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [0.   , 1.   , 0.81 , 0.917, 0.   , 0.576, 1.   , 0.   , 0.   ,\n",
       "         1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 1.   , 0.   , 0.   , 0.   , 1.   ],\n",
       "        [1.   , 0.   , 0.405, 0.917, 0.   , 0.234, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 1.   ],\n",
       "        [0.   , 1.   , 0.472, 0.   , 0.   , 0.115, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 1.   , 1.   , 0.   ],\n",
       "        [0.   , 1.   , 0.321, 0.   , 0.   , 0.378, 0.   , 1.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [1.   , 0.   , 0.472, 0.   , 0.   , 0.115, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [1.   , 0.   , 0.422, 0.   , 0.   , 0.189, 0.   , 1.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [0.   , 1.   , 0.405, 0.   , 0.   , 1.008, 1.   , 0.   , 0.   ,\n",
       "         0.   , 1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 1.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [1.   , 0.   , 0.861, 0.   , 0.   , 0.117, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ]], dtype=float32)>,\n",
       " <tf.Tensor: id=364, shape=(12,), dtype=int32, numpy=array([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0], dtype=int32)>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples, labels = next(iter(train_data))\n",
    "\n",
    "examples, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aJnOromrse57"
   },
   "source": [
    "The examples are in a  two dimensional arrays of 12 items each (the batch size). Each item represents a single row in the original CSV file. The labels are a 1d tensor of 12 values.\n",
    "\n",
    "このサンプルは、（バッチサイズである）12個のアイテムを持つ2次元の配列からできています。アイテムそれぞれは、元の CSV ファイルの1行を表しています。ラベルは12個の値を持つ1次元のテンソルです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DlF_omQqtnOP"
   },
   "source": [
    "## Build the model\n",
    "## モデルの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQoFh16LxtT_"
   },
   "source": [
    "This example uses the [Keras Functional API](https://www.tensorflow.org/alpha/guide/keras/functional) wrapped in a `get_model` constructor to build up a simple model. \n",
    "\n",
    "この例では、[Keras Functional API](https://www.tensorflow.org/alpha/guide/keras/functional) を使用し、単純なモデルを構築するために `get_model` コンストラクタでラッピングしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDM3FIgHNCW3"
   },
   "outputs": [],
   "source": [
    "def get_model(input_dim, hidden_units=[100]):\n",
    "  \"\"\"Create a Keras model with layers.\n",
    "     複数の層を持つ Keras モデルを作成\n",
    "\n",
    "  Args:\n",
    "    input_dim: (int) The shape of an item in a batch. \n",
    "    labels_dim: (int) The shape of a label.\n",
    "    hidden_units: [int] the layer sizes of the DNN (input layer first)\n",
    "    learning_rate: (float) the learning rate for the optimizer.\n",
    "\n",
    "  引数:\n",
    "    input_dim: (int) バッチ中のアイテムの形状\n",
    "    labels_dim: (int) ラベルの形状\n",
    "    hidden_units: [int] DNN の層のサイズ（入力層が先）\n",
    "    learning_rate: (float) オプティマイザの学習率\n",
    "    \n",
    "  Returns:\n",
    "    A Keras model.\n",
    "  \n",
    "  戻り値:\n",
    "    Keras モデル\n",
    "  \"\"\"\n",
    "\n",
    "  inputs = tf.keras.Input(shape=(input_dim,))\n",
    "  x = inputs\n",
    "\n",
    "  for units in hidden_units:\n",
    "    x = tf.keras.layers.Dense(units, activation='relu')(x)\n",
    "  outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "  model = tf.keras.Model(inputs, outputs)\n",
    " \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ce9PRb_LzFpm"
   },
   "source": [
    "The `get_model` constructor needs to know the input shape of your data (not including the batch size).\n",
    "\n",
    "`get_model` コンストラクタは入力データの形状（バッチサイズを除く）を知っている必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qX-DU34ZuKJX"
   },
   "outputs": [],
   "source": [
    "input_shape, output_shape = train_data.output_shapes\n",
    "\n",
    "input_dimension = input_shape.dims[1] # [0] is the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPdtI2ie0lEZ"
   },
   "source": [
    "## Train, evaluate, and predict\n",
    "## 訓練、評価、そして予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8gvw1RE9zXkD"
   },
   "source": [
    "Now the model can be instantiated and trained.\n",
    "\n",
    "これでモデルをインスタンス化し、訓練することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_nm28IzNDTO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.5913 - accuracy: 0.6922\n",
      "Epoch 2/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7895\n",
      "Epoch 3/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7943\n",
      "Epoch 4/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.8086\n",
      "Epoch 5/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8150\n",
      "Epoch 6/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8150\n",
      "Epoch 7/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8150\n",
      "Epoch 8/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8198\n",
      "Epoch 9/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8214\n",
      "Epoch 10/20\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8246\n",
      "Epoch 11/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8246\n",
      "Epoch 12/20\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8246\n",
      "Epoch 13/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8262\n",
      "Epoch 14/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8262\n",
      "Epoch 15/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8278\n",
      "Epoch 16/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8278\n",
      "Epoch 17/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8293\n",
      "Epoch 18/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8357\n",
      "Epoch 19/20\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8373\n",
      "Epoch 20/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.8405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12c940748>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(input_dimension)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QyDMgBurzqQo"
   },
   "source": [
    "Once the model is trained, we can check its accuracy on the `test_data` set.\n",
    "\n",
    "モデルの訓練が終わったら、`test_data` データセットでの正解率をチェックできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eB3R3ViVONOp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22/Unknown - 0s 11ms/step - loss: 0.4420 - accuracy: 0.7992\n",
      "\n",
      "Test Loss 0.44200402430512686, Test Accuracy 0.7992424368858337\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "\n",
    "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTrn_pD90gdJ"
   },
   "source": [
    "Use `tf.keras.Model.predict` to infer labels on a batch or a dataset of batches.\n",
    "\n",
    "単一のバッチは、バッチからなるデータセットのラベルを推論する場合には、`tf.keras.Model.predict` を使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qwcx74F3ojqe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted survival: 11.02%  | Actual outcome:  DIED\n",
      "Predicted survival: 87.44%  | Actual outcome:  SURVIVED\n",
      "Predicted survival: 53.22%  | Actual outcome:  DIED\n",
      "Predicted survival: 8.93%  | Actual outcome:  DIED\n",
      "Predicted survival: 11.14%  | Actual outcome:  DIED\n",
      "Predicted survival: 32.65%  | Actual outcome:  SURVIVED\n",
      "Predicted survival: 9.22%  | Actual outcome:  DIED\n",
      "Predicted survival: 78.39%  | Actual outcome:  SURVIVED\n",
      "Predicted survival: 46.98%  | Actual outcome:  DIED\n",
      "Predicted survival: 46.34%  | Actual outcome:  DIED\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Show some results\n",
    "# 結果のいくつかを表示\n",
    "for prediction, survived in zip(predictions[:10], list(test_data)[0][1][:10]):\n",
    "  print(\"Predicted survival: {:.2%}\".format(prediction[0]),\n",
    "        \" | Actual outcome: \",\n",
    "        (\"SURVIVED\" if bool(survived) else \"DIED\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kMirhswgW_ln"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "csv.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
